% Copyright 2021 Edoardo Riggio

% Licensed under the Apache License, Version 2.0 (the "License");
% you may not use this file except in compliance with the License.
% You may obtain a copy of the License at

% 	http://www.apache.org/licenses/LICENSE-2.0

% Unless required by applicable law or agreed to in writing, software
% distributed under the License is distributed on an "AS IS" BASIS,
% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
% See the License for the specific language governing permissions and
% limitations under the License.

\documentclass{article}

\usepackage{hyperref, amsmath, graphicx, amssymb}
\usepackage{fancyvrb, newverbs, xcolor}

\graphicspath{{./assets/}}
\definecolor{cverbbg}{gray}{0.93}

\newenvironment{cverbatim}
 {\SaveVerbatim{cverb}}
 {\endSaveVerbatim
  \flushleft\fboxrule=0pt\fboxsep=.5em
  \colorbox{cverbbg}{\BUseVerbatim{cverb}}%
  \endflushleft
}

\newenvironment{lcverbatim}
 {\SaveVerbatim{cverb}}
 {\endSaveVerbatim
  \flushleft\fboxrule=0pt\fboxsep=.5em
  \colorbox{cverbbg}{%
    \makebox[\dimexpr\linewidth-2\fboxsep][l]{\BUseVerbatim{cverb}}%
  }
  \endflushleft
}

\newcommand{\ctexttt}[1]{\colorbox{cverbbg}{\texttt{#1}}}
\newverbcommand{\cverb}
  {\setbox\verbbox\hbox\bgroup}
  {\egroup\colorbox{cverbbg}{\box\verbbox}}

\begin{document}
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \Huge
        \textbf{Machine Learning Cheatsheet}
        
        \vspace{0.5cm}
        \LARGE
        
        \vspace{.5cm}
        
        Edoardo Riggio
   		  \vspace{1.5cm}
       
        \vfill
        
        \today
        
        \vspace{.8cm}
          \Large
          Machine Learning - SA. 2022 \\
        Computer Science\\
        Universit\`{a} della Svizzera Italiana, Lugano\\
        
    \end{center}
\end{titlepage}

\tableofcontents

\newpage

\section{Introduction}
What does it mean "to learn"? We have to different definitions, one from a \textbf{statistical perspective}, and one from a \textbf{computer science perspective}.

\begin{itemize}
	\item \textbf{Statistical Perspective}
	\vspace{.2cm} \\
	Vast amounts of data are being generated in many fields. The statistician's job is to make sense of all of this data, extract meaningful patterns and trends, and understand "what the data says". This approach is also known as \textbf{learning from data}.
	
	\item \textbf{Computer Science Perspective}
	\vspace{.2cm} \\
	The field of machine learning is concerned with how to construct computer programs that automatically improve with experience.
\end{itemize}

\subsection{Mitchell's Formalisation}
A computer program is said to learn from \textbf{experience $E$} -- concerning some class of \textbf{task $T$}, and \textbf{performance measurement $P$} -- if its performance at task $T$, as measured by $P$, improves with experience $E$.

\subsection{Models}
\subsubsection{White Box Model}
In this case, both physical laws and structural parameters of the problem are known. A family equation can be derived.

\subsubsection{Grey Box Model}
The physical laws are known in this case, and at least one parameter is unknown. A family of equations can be derived, but the parameters need to be identified.

\subsubsection{Black Box Model}
In this case, the physical laws are unknown. A family of equations cannot be derived.

\subsection{Measures and Measurements}
The operation of measuring an unknown quantity $x_0$ can be modeled as taking an instance -- i.e., a \textbf{measurement} -- $x_i$ at time $i$, with an ad-hoc sensor $S$. \\ \\
Although $S$ has been suitably designed and realized, the physical elements that compose it are far from ideal and introduce uncertainties in the measurement process. As a result, $x_i$ only represents an estimate of $x_0$.

\subsection{Types of Models}
\subsubsection{Additive Model}
The measurement process can be modeled as:
\[ x = x_0 + \eta ~~~~~\text{where}~\eta = f_n(0, \sigma^2_\eta) \]
Where $\eta$ is an independent and identically distributed random variable, the model assumes that the i.i.d. noise does not depend on the working point $x_0$.

\subsection{Multiplicative Model}
The measurement process can be modeled as:
\[ x = x_0 (1 + \eta) ~~~~~\text{where}~\eta = f_n(0, \sigma^2_\eta) \]
Where $\eta$ is an independent and identically distributed random variable, the noise, in this case, depends on the working point $x_0$. In absolute terms, the impact of the noise on the signal is $x_0 \eta$, but the relative contribution is $\eta$ -- which does not depend on $x_0$.

\subsection{Supervised Learning}
In a supervised learning framework, we have the following elements: a \textbf{concept to learn}, a \textbf{teacher}, and a \textbf{student}.

\subsubsection{Regression}
The goal of regression is to determine the function that explains the given instances -- \textbf{measuremets}. The student proposes a family of models $f(\theta, x)$, and after a learning procedure, the "best" model $f(\hat \theta, x)$ is found.

\subsubsection{Classification}
The goal of classification is to determine the function -- \textbf{model} -- that partitions the input -- \textbf{measurements} -- into classes. The student proposes a family of models $f(\theta, x)$, and after a learning procedure, the "best" model $f(\hat \theta, x)$ is found.

\subsubsection{Prediction}
The goal of prediction is to tell us which data -- \textbf{measurements} -- will come next, possibly along with a confidence level. The student proposes a family of models $f(\theta, x)$, and after a learning procedure, the "best" model $f(\hat \theta, x)$ is found.

\subsection{Features}
We might want to extract features from the measurements to ease the learning task. The features must:
\begin{itemize}
	\item Provide a compact representation of inputs
	\item Be particularly advantageous if we have prior information to take advantage of
	\item Be reduced to a minimal set before processing them for task solving
\end{itemize}

\subsection{Unsupervised Learning}
The goal of unsupervised learning is to build a representation of data. During its operational life, given an input, the machine provides information that can be used for decision-making.

\section{Linear Regression}
To prepare a linear regression model, several techniques can be used. The most popular being the \textbf{Least Mean Square (LMS)}, and the \textbf{Gradient Descent}. \\ \\
Linear models are good when we have the following conditions:
\begin{itemize}
	\item The data is generated by a linear model
	\item The dataset is small
	\item The data is sparse
	\item The uncertainty is high
\end{itemize}

\subsection{Muliple Linear Regression}
We are given a set of points:
\[ \{ (x_1, y_1), (x_2, y_2), \dots, (x_n, y_n) \} ~~~~~ \text{where}~x \in \mathbb{R}^d, y \in 	\mathbb{R} \]
This is known as the \textbf{training set}. We now assume that the unknown function that generates the data is linear. Moreover, we assume that there is a gaussian uncertainty affecting the measurements. The model is given as:
\[ y(x) = \theta^0_1 + \theta^0_2 z_2 + \dots + \theta^0_d z_d ~~~~ \text{where}~\theta^0 \in \mathbb{R}, \eta = N(0, \sigma^2_\eta) \]
Which can be written in its canonical form:
\[ y(x) = x^T \theta^0 + \eta ~~~~~ \text{where}~x^T = \begin{bmatrix} 1 & z_2 & \cdots & z_d \end{bmatrix}, \theta^{0^T} = \begin{bmatrix} \theta^0_1 & \theta^0_2 & \cdots & \theta^0_d \end{bmatrix} \]
Both the optimal parameters and the variance of the noise are unknown. Since we know that the system model is linear, the family of models which best fits the data is:
\[ \hat y(x) = f(\theta, x) = x^T \theta \]
In order to determine the best parameters, we estimate them:
\[ f(\hat \theta, x) = x^T \hat \theta \]

\subsubsection{Least Mean Square}
The main idea of this procedure is to select the linear function that minimizes the average distance between the given points and the linear function. \\ \\
The \textbf{performance function} of this method is the following:
\[ V_n(\theta) = \frac{1}{n} \sum^n_{i=1}(y(x_i) - f(\theta, x_i))^2 \]
Therefore, the parameter vector $\hat \theta$ minimizing the performance function is the following:
\[ \hat \theta  = \arg\min_{\theta \in \Theta} V_n(\theta) \]

\subsubsection{Parameter Estimation}
By grouping the data into vectors $X$ -- of all $x$ values -- and $Y$ -- of all $y$ values, we can rewrite the formula above in its canonical form:
\begin{align*}
	V_n^*(\theta) &= \sum^n_{i=1} (y(x_i) - x^T_i \theta)^2 \\
	&= (Y - X\theta)^T (Y - X\theta) 
\end{align*}
\textbf{Stationary points} are those for which:
\[ \frac{\partial V_n^*(\theta)}{\partial \theta} = -2X^T Y + 2X^T X \theta = 0 \]
Therefore, the parameter vector $\hat \theta$ minimizing the performance function is the following:
\[ \hat \theta = (X_TX)^{-1}X^TY \]
And the best approximating model is:
\[ f(\hat \theta x) = x^T\hat\theta \]

\subsection{Performance at Task}
In order to test the model, we need to use another set of unseen data. This is because the \textbf{performance at task}:
\[ V_n(\hat\theta) = \frac{1}{n} \sum^n_{i=1}(y(x_i) - f(\theta, x_i))^2 \]
It is biased to the training set. For this reason, we consider another set of data -- different from the training set -- and call it \textbf{test set}:
\[ \{ (\bar x_1, \bar y_1), (\bar x_2, \bar y_2), \dots, (\bar x_l, \bar y_l) \} \]
And evaluate the performance at task on it:
\[ V_l(\hat\theta) = \frac{1}{l} \sum^l_{i=1}(\bar y_i - \bar x^T\hat\theta)^2 \]

\subsection{Cross-Validation}
Cross-validation provides a means to assess the performance of a model. This method can also be considered for model selection -- with some care. In the latter case, we consider the model that minimizes
\[ V_l(\hat\theta) = \frac{1}{l} \sum^l_{i=1}(\bar y_i - \bar x^T\hat\theta)^2 \]

\subsection{Properties}
Under the linear framework presented earlier, it can be proved that both implications hold true:
\[ \lim_{n \rightarrow \infty} \hat\theta = \theta^0 \]
\[ \lim_{l \rightarrow \infty} V_l(\hat\theta) = \sigma^2_\eta \]
In addition, assuming that $n$ training couples are given, then it can be proved that:
\[ Var(\hat\theta) = (X^TX)^{-1}\sigma^2_\eta ~~~~~ \text{with}~\hat\sigma^2_\eta = \frac{1}{n - d} \sum^n_{i = 1}(y(x_i) - f(\hat\theta, x_i))^2 \]
If a parameter is smaller than twice its standard deviation, it must be set to 0. After which, we re-evaluate the performance and decide whether to keep it. This is known as \textbf{Occam's razor strategy}.

\subsection{Ridge Regression}
Ridge regression aims at pushing as many parameters as possible towards zero. This is done by adding a shrinking penalty to the loss function. The \textbf{MSE} training performance mesure
\[ V_n(\theta) = \frac{1}{n} \sum^n_{i=1}(y_i - x_i^T\theta)^2 \]
Now becomes
\[ V_{Ridge}(\theta) = \frac{1}{n} \sum^n_{i=1}(y_i - x_i^T\theta)^2 + \lambda \sum^d_{i=2}\theta^2_i \]
Where $\lambda$ is a hyperparameter weighting the two contributions. A smaller $\lambda$ gives more importance to accuracy, while a high $\lambda$ priviledges a smaller number of parameters in the model. A tradeoff can be obtained by estimating and appropriate $\lambda$ thanks to the \textbf{validation set}.

\subsection{Lasso Regression}
Lasso regression also aims at pushing as many parameters as possible towards zero. In this case, however, we penalize the parameter itself rather than its square. The \textbf{MSE} now is:
 \[ V_{Lasso}(\theta) = \frac{1}{n} \sum^n_{i=1}(y_i - x_i^T\theta)^2 + \lambda \sum^d_{i=2}|\theta_i| \]
 The optimization problem is not convex anymore, and the loss function is not differentiable. This makes the problem computationally complex and solvable only via optimization techniques such as quadratic programming.
 
 \subsection{Final Prediction Error}
 The expected prediction error is computed as follows:
 \[ FPE = \frac{n+d}{n-d}\sum^n_{i=1}(y(x_i) - f(\hat\theta, x_i))^2 \]
 This measurement can be used for both model selection -- only on hierarchical family of models, and for assessing the performance of unseen data.

\end{document}

































